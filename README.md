## Алгоритм прямого поиска
Максимально простой алгоритм поиска подстроки в строке.
Его основная идея заключается в последовательном прогоне подстроки без какой-либо предобработки. Каждый символ строки сравнивается с первым символом подстроки, затем, если символы совпадают запускается цикл последовательно проверяющий оставшиеся символы подстроки и соответствующие символы строки. В случае всех успешных проверок возвращается позиция, на которой запустился второй цикл, в противном случае проверка продолжается с позиции после этой. Если подстрока не была найдена - вернется _"неправильное значение"_, в моем случае это `std::string::npos`.

Блок-схема алгоритма:

![Блок-схема алгоритма](https://raw.githubusercontent.com/mocurin/test/master/pics/Naive_algorithm.svg?sanitize=true)

В _лучшем случае_ время работы алгоритма - **O(N)**, где N - длина строки. Все бы ничего, если бы не время работы в _худшем случае_ - **O(N*M)**, где M - длина подстроки. Причиной тому служат многократные прогоны одной и той же позиции в строке, ведь уже проверенные позиции никак не помечаются и не пропускаются

Плюсы:

 - Исключительная простота написания
 - Малое выделение памяти (нужно всего 2 счетчика и опционально две переменных, отражающих длину строки и подстроки)

Минусы:
 - Большое время работы на определенных данных
 
## Алгоритм Рабина-Карпа
Алгоритм, смысл которого заключается в использовании _хеширования_.
Сначала вычисляется хеш подстроки и первых элементов строки, в которой производится поиск, затем хеши сравниваются. Если хеши совпадают - начинается посимвольная проверка, в противном случае из старого хеша считается новый, для следующей подстроки, и хеши снова сравниваются.

В то время как алгоритм хеширования может быть любым кольцевым хешем, наилучшим выбором будет именно **полиномиальный хеш**, чьим преимуществом является относительно низкая вероятность коллизий и быстрый пересчет хеша последовательных подстрок. Как раз его изначально предлагали Рабин и Карп.
Короче говоря, строка представляется как полином с основанием _X_ (в идеале - случайное число от 2 до Q, я же брал размер алфавита) и на каждом действии (дабы не переполнить тип) получившееся число берется по модулю _Q_ (какое-то простое число). Ключевой особенностью этого хеша является его пересчет - нужно всего лишь вычесть первый элемент подстроки, умноженный на наибольшую степень *Х*, домножить на *Х* и прибавить добавленный элемент (по факту, домноженный на *Х^0^*). И не забыть взять по модулю, а то мало ли чего. Кстати, где-то тут возникает потребность "исправить" число, ведь оно с легкостью может выйти за границы при вычитании.

Время работы алгоритма в _лучшем случае_ - **O(N)**, в _худшем_ опять же, около **O(N*M)**, но худший случай возникает лишь из-за хеша, допускающего большое количество коллизий. Тот же полиномиальный хеш с большой долей вероятности гарантирует, что такого не случится.

Блок-схема алгоритма:

![Блок-схема алгоритма](https://raw.githubusercontent.com/mocurin/test/master/pics/RK_Algorithm.svg?sanitize=true)

Хеширование строки:

![Хеширование строки](https://raw.githubusercontent.com/mocurin/test/master/pics/String%20hash.svg?sanitize=true)

Вычисление степени:

![Вычисление степени](https://raw.githubusercontent.com/mocurin/test/master/pics/Count%20biggest%20power.svg?sanitize=true)

Рехеширование:

![Рехеширование](https://raw.githubusercontent.com/mocurin/test/master/pics/Rehash.svg?sanitize=true)

Плюсы:
 - При правильном выборе хеш-функции время работы стремится к O(N)
 - Согласно википедии, отлично подходит для нахождении _множества_ образцов в тексте, позволяя находить их за O(N + K), где K - количество образцов, вместо O(N*K) у других. Он может уступать алгоритму Ахо-Корасик в худшем случае, но его, по идее, куда проще реализовать.

Минусы:
  - Подсчет хеша - в частности взятие по модулю в нем - очень громоздкая и медленная операция, а посему работает он медленнее того же КМП.
 
## Алгоритм Кнута-Морриса-Пратта
 
 Алгоритм, смысл которого заключается в правильной предобработке подстроки и создании особого массива, который будет использоваться как указание на какие позиции нужно возвращаться, в случае расхождения подстроки и строки, что полностью исключает какие-либо повторные проверки позиций.
 
В предобработке подстроки создается массив такой же длины как и подстрока, в каждый элемент которого последовательно заносится длина наибольших равных _префикса_ и _суффикса_ подстроки до этой позиции, включая ее. Затем, при сравнении подстроки со строкой, натыкаясь во время проверки подстроки можно будет откатиться не как в прямом алгоритме - к самому началу, а к определенной позиции, так как мы знаем сколько символов нужно пропустить.

Блок-схема алгоритма:

![Блок-схема алгоритма](https://raw.githubusercontent.com/mocurin/test/master/pics/KMP_algorithm.svg?sanitize=true)

Функция предобработки строки:

![Функция предобработки подстроки](https://raw.githubusercontent.com/mocurin/test/master/pics/Prefix%20function.svg?sanitize=true)

Время работы алгоритма что в _лучшем_, что в _худшем_ случаях - **O(N+M)**, то есть: обработка подстроки + обработка строки.

Плюсы:

 - Простота написания
 - Считается одним из самых быстрых алгоритмов из-за своей маленькой функции предобработки

Минусы:

- Выделение памяти в размере длины подстроки. Это не критично до определенного момента, но это все еще выделение памяти

## UPD
Я поменял метод тестирования - теперь подстрока не "прилипает" к концу исходной строки. Поэтому пришлось найти новый случай сложной строки (т.е. максимизировать количество перепроверок и коллизий в исходной строке). Теперь в качестве сложной строки выступает слово Туе-Морса. Такое слово строится из двух букв последовательной конкатенацией побуквенно инвертированной (для a, b: 'a'->'b', 'b'->'a') строки к самой себе же.  Вот первые пять таких строк:
```
T0=a
T1=ab
T2=abba
T3=abbabaab
T4=abbabaabbaababba
````
Почему именно она? Тут неверотяно много повторений. ~~К тому же, я где-то читал что она "ломает" хэши, в которых модуль берется по какой-то степени двойки и в результате получается много коллизий. К моему алгоритму это не имеет никакого отношения, но все же~~
Должно быть достаточно.
Первый график показывает, зависимость от размера строки:
![График 1](https://github.com/mocurin/2-lab-02-report/blob/master/pics/Varying_str.png)
Опять же, 1000 повторений, размер строки варьируется от 8 до 8192, подстроки в этот раз берутся в случайном месте. Особой разницы между простой и сложной строкой на этом графике не видно.
По пунктам:
 - Библиотечный алгоритм бесспорно на высоте. Он показывает одинаковое время работы на строках различной длины, хотя мне не совсем понятно как и почему.
 - Прямой алгоритм, ожидаемо, показывает что работает хуже на сложной строке в силу растущего количества повторений с ростом размера строки.
 - Рабин-Карп оказался худшим. Это, вне сомнений, происходит из-за тяжелой функции предобработки. Хэширование в ней работает засчет взятия по модулю, а это, насколько я понимаю, тяжелая операция. График для сложной строки расположен ниже графика для простой в основном из-за того, что в строке с таким количеством повторений велик шанс встретить подобную подстроку еще до ее реального положения. Это та причина, по которой я судил о разнице между графиками абзацем ранее.
 - Кнут-Моррис-Пратт показывает неплохие результаты, но в строке без каких-либо сложностей его обходит прямой алгоритм. Происходит это, опять же, из-за предобработки подстроки в этом алгоритме - она помогает проходить сложные строки, но на простых лишь тратит время, ведь там после ее создания она даже не используется.
 
Но самое интересное на следующем графике:
![График 2](https://github.com/mocurin/2-lab-02-report/blob/master/pics/Varying_substr.png)
1000 повторений, строка размером 2048 символов и варьирующийся от 8 до 2048 размер подстроки.
 - Библиотечный алгоритм опять показывает одинаковое время работы на разных данных
 Стоит отметить, что результаты получены для release версии. В debug'e же библиотечный алгоритм мало того, что работал медленнее, так еще и на сложной строке показывал в среднем в 6-7 раз большее время чем на простой. Одни загадки. 
 - Прямой алгоритм снова выигрывает засчет отсутствия предобработки, но на средних сложных строках (на графике это 1024) он работает в два раза медленнее чем на простой строке. Объясняется это тем, что чем больше строка, тем сложнее встретить ее копию в строке до нее самой, но при всем этом случается большое количество коллизий, что и замедляет работу. После 1024 символов алгоритм просто начинает  встречать искомую строку раньше и общее количество перепроверок начинает медленно стремиться к нулю. Этот "горб", к слову, был и на предыдущих графиках, только с тем методом он был куда более явным
 - График для Рабина-Карпа показывает как больно дается алгоритму дополнительная нагрузка в виде предобработки для большой подстроки. На маленьких значениях искомая строка снова встречается раньше, чем она расположена на самом деле.
 - КМП так же страдает из-за предобработки, пусть и не так явно как РК. Закономерно на большой подстроке время работы увеличивается.
 
 Теперь график для случаев, когда искомая подстрока просто не встречается в строке и алгоритмам приходится проходить всю строку целиком:
 ![График 3](https://github.com/mocurin/2-lab-02-report/blob/master/pics/Varying_str_inexsistant.png)
 1000 потворений, размер строк варьирутся от 8 до 8192, подстрока случайна, но в этот раз не является настоящей подстрокой. За основу берется настоящая, но к ней в конец добавляется символ, однозначно не встречающийся в последовательности. Несколько костыльно, но позволяет по-настоящему оценить работу на сложных строках, ведь теперь перепроверки не компенсируются подстрокой, находящейся до настоящей подстроки
По порядку:
 - График библиотечного алоритма. Он есть, вроде бы достаточно
 - График прямого алгоритма. На длине в 8192 символов алгоритм справлялся со сложной строкой в три раза дольше чем с простой. На первом графике это различие было примерно в два раза. Подвижки есть, но говорит это ровно о том же самом что и в прошлый раз
 - С графиком для РК происходят более интересные вещи. График для сложной строки просто совпал с графиком для простой. Происходит это из-за того, что РК чужды проблемы с повторяющимися строками - лишь бы не было одинаковых хэшей. Таким образом ему все равно какую строку обрабатывать (до тех пор пока не будет подобрана такая, чтобы постоянно собирать коллизии). Жаль, что работает все еще медленнее других.
 - С КМП аналогичная ситуация. Графики почти совпали. Почти - график для сложной строки оказался чуть ниже. Скорее всего это издержки выбранной мной реализации и обрабатывать строки с большим количеством повторений проще.
 
## Новое заключение 
Прямой алгоритм не так уж плох. И работает хорошо до тех пор, пока данные не становятся "сложными" - не появляется большое количество повторений. РК, наверняка, так же хорош, но мне было бы интересно посмотреть на такую его релизацию, которая сможет составить конкуренцию хотя бы моей реализации КМП. Сам КМП же и пишется и просто и в целом очень хорошо показывает себя, так что лично я бы выбрал его.
